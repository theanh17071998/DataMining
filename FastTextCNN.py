import io
import numpy as np
import pandas as pd
import string
import torch
from transformers import AutoModel, AutoTokenizer
import tensorflow as tf

from sklearn.model_selection import train_test_split


def load_fasttext(path):
    num_words = 100000
    fin = io.open(path, 'r', encoding='utf-8',
                  newline='\n', errors='ignore')
    n, d = fin.readline().split()
    data = {}
    i = 0
    for line in fin:
        i += 1
        tokens = line.rstrip().split(' ')
        data[tokens[0]] = np.array([float(val) for val in tokens[1:]])
        data[tokens[0]] /= np.linalg.norm(data[tokens[0]])
        if i > num_words:
            break

    return data
DOMAIN_TRAIN = {
    'mebe_tiki': 'giá,dịch_vụ,an_toàn,chất_lượng,ship,chính_hãng'
}
def model(domain,label):
    data_ = load_fasttext('D:\\DataScience\\Deeplearning\\cc.vi.300.vec')
    review = pd.read_csv("D:\\DataScience\\Deeplearning\\{}.csv".format(domain))
    review.isnull().values.any()
    data_an_toan = zip(review['cmt'], review['{}'.format(label)])
    data = pd.DataFrame(data_an_toan, columns=["review", "sentiment"])
    data = data[data['sentiment'] != 0]
    X = []
    sentences = list(data['review'])
    for sen in sentences:
        X.append(sen)
    y = data['sentiment']
    y = np.array(list(map(lambda x: 1 if x == 1 else 0, y)))
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    a = []
    for text in X_train:
        arr_text = text.split(' ')
        mt = []
        for ar in arr_text:
            if ar in data_:
                mt.append(data_[ar])
            else:
                mt.append(np.zeros(300))
        print(len(mt))
        a.append(mt)
    xtest1 = []
    for text in X_test:
        arr_text = text.split(' ')
        mt = []
        for ar in arr_text:
            if ar in data_:
                mt.append(data_[ar])
            else:
                mt.append(np.zeros(300))
        xtest1.append(mt)
    xtest = xtest1
    xtrain = a
    imble = 0
    imble1 = 0
    for k in xtrain:
        imble = max(imble, len(k))
    for k in xtest:
        imble1 = max(imble1, len(k))
    imble = max(imble1, imble)
    xtrain_new = []
    for k in xtrain:
        xtrain_new.append(np.hstack([k, np.zeros([1, imble - len(k), 300])])[0])
    xtrain_new = np.array(xtrain_new)
    print(xtrain_new.shape)
    xtrain_new_test = []
    for k in xtest:
        xtrain_new_test.append(np.hstack([k, np.zeros([1, imble - len(k), 300])])[0])
    xtrain_new_test = np.array(xtrain_new_test)
    y_train = np.array(y_train)
    y_test = np.array(y_test)


if __name__ == '__main__':
    data_ = load_fasttext('D:\\DataScience\\Deeplearning\\cc.vi.300.vec')
    review = pd.read_csv("D:\\DataScience\\Deeplearning\\mebe_tiki.csv")
    review.isnull().values.any()
    data_an_toan = zip(review['cmt'], review['an_toàn'])
    data = pd.DataFrame(data_an_toan, columns=["review", "sentiment"])
    data = data[data['sentiment'] != 0]
    X = []
    sentences = list(data['review'])
    for sen in sentences:
        X.append(sen)
    y = data['sentiment']
    y = np.array(list(map(lambda x: 1 if x == 1 else 0, y)))
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    a = []
    for text in X_train:
        arr_text = text.split(' ')
        mt = []
        for ar in arr_text:
            if ar in data_:
                mt.append(data_[ar])
            else:
                mt.append(np.zeros(300))
        print(len(mt))
        a.append(mt)
    xtest1 = []
    for text in X_test:
        arr_text = text.split(' ')
        mt = []
        for ar in arr_text:
            if ar in data_:
                mt.append(data_[ar])
            else:
                mt.append(np.zeros(300))
        xtest1.append(mt)
    xtest = xtest1
    xtrain = a
    imble = 0
    imble1 = 0
    for k in xtrain:
        imble = max(imble, len(k))
    for k in xtest:
        imble1 = max(imble1, len(k))
    imble = max(imble1, imble)
    xtrain_new = []
    for k in xtrain:
        xtrain_new.append(np.vstack((((np.array(k))),np.zeros((imble-len(k),300)))))
    xtrain_new = np.array(xtrain_new)
    print(xtrain_new.shape)
    xtrain_new_test = []
    for k in xtest:
        xtrain_new_test.append(np.vstack((((np.array(k))),np.zeros((imble-len(k),300)))))
    xtrain_new_test = np.array(xtrain_new_test)
    y_train = np.array(y_train)
    y_test = np.array(y_test)

    model_input = tf.keras.layers.Input(shape=(imble, 300))
    output_cnn_2 = tf.keras.layers.Conv1D(128, 2)(model_input)
    output_cnn_2 = tf.keras.layers.MaxPool1D(imble-1)(output_cnn_2)
    output_cnn_2 = tf.keras.layers.Flatten()(output_cnn_2)

    output_cnn_3 = tf.keras.layers.Conv1D(128, 3)(model_input)
    output_cnn_3 = tf.keras.layers.MaxPool1D(imble-2)(output_cnn_3)
    output_cnn_3 = tf.keras.layers.Flatten()(output_cnn_3)

    output_cnn_4 = tf.keras.layers.Conv1D(128, 4)(model_input)
    output_cnn_4 = tf.keras.layers.MaxPool1D(imble-3)(output_cnn_4)
    output_cnn_4 = tf.keras.layers.Flatten()(output_cnn_4)

    output_cnn = tf.concat([output_cnn_2, output_cnn_3, output_cnn_4], axis=-1)

    output_mlp = tf.keras.layers.Dense(128)(output_cnn)
    output_mlp = tf.keras.layers.Dense(64)(output_mlp)

    final_output = tf.keras.layers.Dense(1, activation='sigmoid')(output_mlp)

    model = tf.keras.models.Model(inputs=model_input, outputs=final_output)

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    model.summary()
    model.fit(xtrain_new, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)
    score = model.evaluate(xtrain_new_test, y_test, verbose=1)
    result_xtest1 = model.predict(xtrain_new_test)
    result_xtest1 = np.array(result_xtest1.reshape(len(y_test)))

    tp = 0
    fp = 0
    fn = 0
    for k, k1 in zip(y_test, result_xtest1):
        if k == -1 and k1 < 0.5:
            tp += 1
        elif k == -1:
            fn += 1
        elif k1 < 0.5:
            fp += 1

    p = tp / (tp + fp)
    r = tp / (tp + fn)
    f1 = 2 * p * r / (p + r)

    print('p:', p)
    print('r:', r)
    print('f1:', f1)


    print("Test Score:", score[0])
    print("Test Accuracy:", score[1])
